{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "txtshortner.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HjTViaTY4YY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image OCR"
      ]
    },
    {
      "metadata": {
        "id": "pEEgxE8S4a_v",
        "colab_type": "code",
        "outputId": "122bed5f-c7d2-4336-e672-0d0b8426a747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "!tesseract download.png stdout -l eng --oem 1 --psm 3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning. Invalid resolution 0 dpi. Using 70 instead.\n",
            "Estimating resolution as 252\n",
            "There is a rikshaw-gang\n",
            "operating in surat which is\n",
            "targeting svnit students. There\n",
            "will be already 2-3 people\n",
            "sitting in auto. They will first\n",
            "distract you and then they will\n",
            "ask you to get out from auto\n",
            "and in between this, they will\n",
            "stole your mobile. | m just\n",
            "making all of you aware of this,\n",
            "as per the recent 3 cases\n",
            "happened in our college. And\n",
            "the police is also not\n",
            "supporting them instead have\n",
            "asked to give the footage and\n",
            "pics to them from anywhere.\n",
            "So be aware while\n",
            "sitting in sharing\n",
            "rickshaws.\n",
            "\f"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bAKks4-0pfjC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Summerizer"
      ]
    },
    {
      "metadata": {
        "id": "Is36VOTr--Be",
        "colab_type": "code",
        "outputId": "a0bce69a-d909-4132-dcce-c0c6a10fe38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt') \n",
        "import re\n",
        "\n",
        "df = pd.read_csv(\"data.csv\", index_col=0)    #common"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GaBaYz78roWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize        #common\n",
        "sentences = [sent_tokenize(x) for x in df['message']]\n",
        "sentences = [y for x in sentences for y in x] # flatten list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJZkbB-B-Wse",
        "colab_type": "code",
        "outputId": "62d54498-2824-472c-c799-4e83d22c9703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"{0} unread chats found with total of {1} sentences in it.\".format(df.shape[0], len(sentences)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 unread chats found with total of 22 sentences in it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jvzOmKtZsdv9",
        "colab_type": "code",
        "outputId": "d2926fa6-f8c8-41a5-fdd9-2abd05ea3bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip  #once\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-26 18:29:53--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-03-26 18:29:53--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.52MB/s    in 2m 10s  \n",
            "\n",
            "2019-03-26 18:32:03 (6.35 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUvaSG0WsgE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract word vectors #common\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSwysh_kthi7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove punctuations, numbers and special characters\n",
        "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
        "\n",
        "# make alphabets lowercase\n",
        "clean_sentences = [s.lower() for s in clean_sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulZe5YZIt0kL",
        "colab_type": "code",
        "outputId": "a6908f8d-a447-4394-daac-4643687ecb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords') #downloading the stop_words\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vE7emw80uMy2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to remove stopwords #once\n",
        "def remove_stopwords(sen):\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "\n",
        "# remove stopwords from the sentences  #common\n",
        "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q3Gr0BqSuiX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_vectors = []\n",
        "for i in clean_sentences:\n",
        "  if len(i) != 0:\n",
        "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "  else:\n",
        "    v = np.zeros((100,))\n",
        "  sentence_vectors.append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PH2lCMD7u2jp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# similarity matrix\n",
        "sim_mat = np.zeros([len(sentences), len(sentences)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I9wmgnTtwFpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences)):\n",
        "    if i != j:\n",
        "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SLxCxv3-wpO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import networkx as nx   # Converting sim_mat into a graph\n",
        "\n",
        "nx_graph = nx.from_numpy_array(sim_mat)\n",
        "scores = nx.pagerank(nx_graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmSABbuWQO3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bb81abd-33c1-47cf-eaad-b109b3c0c42f"
      },
      "cell_type": "code",
      "source": [
        "!sudo pip install termcolor\n",
        "\n",
        "class color:\n",
        "    PURPLE = '\\033[95m'\n",
        "    CYAN = '\\033[96m'\n",
        "    DARKCYAN = '\\033[36m'\n",
        "    BLUE = '\\033[94m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    END = '\\033[0m'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kg1RNkk_wy80",
        "colab_type": "code",
        "outputId": "67b9ea2a-f3a4-4e15-af4b-4d4881da9472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "# Chat Analytics\n",
        "print(color.RED+\"{0}\".format(\"Atharv\")+color.END+\" has {0} chats\".format(6))\n",
        "print(color.RED+\"{0}\".format(\"Krunal\")+color.END+\" has {1} chats\".format(\"Krunal\", 16))\n",
        "print(\"\\nTotal \"+color.GREEN+\"{0}\".format(22)+color.END+\" chat messages received, with {0} participants\\n\".format(2))\n",
        "print(color.BOLD+\"Summary:\\n\"+color.END)\n",
        "for i in range(7):\n",
        "  print(ranked_sentences[i][1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[91mAtharv\u001b[0m has 6 chats\n",
            "\u001b[91mKrunal\u001b[0m has 16 chats\n",
            "\n",
            "Total \u001b[92m22\u001b[0m chat messages received, with 2 participants\n",
            "\n",
            "\u001b[1mSummary:\n",
            "\u001b[0m\n",
            "Everything is totally free....\n",
            "\n",
            "After completion of this Training studants can get direct entry to Diploma Engineering in eligible stream\n",
            "\n",
            ":pray:my humble request to you, if you find good students with financial poor family in our society ( Eg.Our maid's childrens) please communicate below advertisement to them or give below mentioned cell no.\n",
            "Senior Analytics Manager - Aasaanjobs.pdf\n",
            "You can even refer your friends for this role.\n",
            "We are searching such students who are interested in Technical career and due to family’s financial problems they couldn't continue their career.\n",
            "Please fill up this form, it would help us a lot.\n",
            "Hey,\n",
            "\n",
            "WhatsApp Messenger is a fast, simple and secure app that I use to message and call the people I care about.\n",
            "SIEMENS India has inaugurated a new \" SIEMENS Technical Acadamy\" at Airoli , Mumbai for those students who want to do career in Technical and Technology.\n",
            "This SIEMENS Training centre is providing Technical Skills in Two trades Electrical & Fitter and also giving stipend (7500/- per month in 1st year, 8500/- per month in 2nd year) and canteen facility.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FzXzX23U-A3h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
